{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device found.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "torchvision.disable_beta_transforms_warning()\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import kornia\n",
    "from IPython import display\n",
    "import cv2 as cv\n",
    "\n",
    "os.environ[\"COLAB\"] = \"False\"\n",
    "# Changing directory into aml_itu\n",
    "if os.getcwd().split('/')[-1] != 'aml_itu': os.chdir(os.path.abspath('.').split('aml_itu/')[0]+'aml_itu')\n",
    "\n",
    "from utils.helpers import *\n",
    "from utils.StatefarmPytorchDataset import StateFarmDataset\n",
    "\n",
    "# Setting up device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print (f\"GPU is available\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print('MPS device found.')\n",
    "else:\n",
    "    print (\"No GPU available, using CPU instead\")\n",
    "    \n",
    "    \n",
    "from utils.models.EfficientNet import EfficientNet\n",
    "from utils.models.TinyVGG import TinyVGG\n",
    "from utils.pipelines.image_transformation import image_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helpers, utils, variables, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "config = load_config(eval(os.environ[\"COLAB\"]))\n",
    "\n",
    "# IMG Transformations\n",
    "augmentations =  v2.Compose([\n",
    "    T.Resize((168, 224), antialias=True),\n",
    "    v2.ToDtype(torch.float32, scale=True)])\n",
    "\n",
    "# Initialize variables\n",
    "frame_rate = 10  # frames per second\n",
    "duration = 20  # duration of video in seconds\n",
    "image_folder = f\"{config['outputs']}/tmp_video_generator\"  # Folder to save images\n",
    "video_name = 'predictions.mp4'  # Output video name\n",
    "\n",
    "# Ensure the folder for images exists\n",
    "os.makedirs(image_folder, exist_ok=True)\n",
    "\n",
    "# IMG Transformations\n",
    "augmentations =  v2.Compose([\n",
    "    T.Resize((168, 224), antialias=True),\n",
    "    v2.ToDtype(torch.float32, scale=True)])\n",
    "\n",
    "# Generate cam\n",
    "cam = cv.VideoCapture(0)\n",
    "\n",
    "# Extract frame from camera\n",
    "def get_frame(cam):\n",
    "    \"\"\"Capture frame from webcam\"\"\"\n",
    "    _, frame = cam.read() \n",
    "    frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Transform to tensor \n",
    "    frame = kornia.image_to_tensor(frame)\n",
    "    return frame\n",
    "\n",
    "def batch_image(frame):\n",
    "    \"\"\"Transform image to batch\"\"\"\n",
    "    frame = frame.unsqueeze(0)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class weighted_prediction:\n",
    "    def __init__(self, config, n=10):\n",
    "        \"\"\"Class takes pytorch predictions as input and outputs a weighted prediction over the last n frames\"\"\"\n",
    "        self.n = n\n",
    "        self.config = config\n",
    "        self.predictions = None\n",
    "        self.weighted_predictions = []\n",
    "\n",
    "    # Append prediction to list\n",
    "    def __call__(self, prediction):\n",
    "        \"\"\"Performs the weighted average\"\"\"\n",
    "        # Append prediction to list\n",
    "        if self.predictions is None:\n",
    "            self.predictions = prediction.detach().cpu().numpy()\n",
    "        else:\n",
    "            self.predictions = np.vstack((self.predictions, prediction.detach().cpu().numpy()))\n",
    "\n",
    "        # If their arent enought predictions, return nothing\n",
    "        if self.predictions.shape[0] < self.n:\n",
    "            self.weighted_predictions.append(None)\n",
    "            return None\n",
    "        \n",
    "        # Else return the weighted prediction over the last n frames\n",
    "        else:\n",
    "            self.weighted_predictions.append(np.argmax(self.predictions[-self.n:, :].mean(axis=0)))\n",
    "            return self.weighted_predictions[-1]\n",
    "            \n",
    "    def map_labels(self, prediction):\n",
    "        \"\"\"Maps the prediction to the correct class\"\"\"\n",
    "        if prediction is None:\n",
    "            return 'Out of scope'\n",
    "        return config['dataset']['class_mapping'][f'c{prediction}']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EfficientNet_b0_AdamW_20231204_103512_epoch_10.pt'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "last_efficientnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path and directory files\n",
    "efficinetnet_path = os.path.join(config['outputs']['path'], 'EfficientNet_b0_AdamW')\n",
    "efficientnet_models = os.listdir(os.path.join(config['outputs']['path'], 'EfficientNet_b0_AdamW'))\n",
    "last_efficientnet_model = sorted(efficientnet_models)[-1]\n",
    "\n",
    "efficient = EfficientNet()\n",
    "\n",
    "# Load parameters from last model\n",
    "efficient.load_state_dict(torch.load(os.path.join(efficinetnet_path, last_efficientnet_model)))\n",
    "\n",
    "# Set model to eval\n",
    "efficient = efficient.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TinyVGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path and directory files\n",
    "TinyVGG_path = os.path.join(config['outputs']['path'], 'TinyVGG_500k')\n",
    "TinyVGG_file = 'TinyVGG_500k_final.pt'\n",
    "\n",
    "# initalize model\n",
    "tinyvgg = TinyVGG()\n",
    "\n",
    "# Load parameters from last model\n",
    "tinyvgg.load_state_dict(torch.load(os.path.join(TinyVGG_path, TinyVGG_file)))\n",
    "\n",
    "# Set model to eval\n",
    "tinyvgg = tinyvgg.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Looper\n",
    "This class will take in predictions, and return the mean predictions over the last x amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_loop(model, \n",
    "                   image_size,\n",
    "                   weighted_frames = 10,\n",
    "                   total_seconds=10,\n",
    "                   device=device):\n",
    "    \"\"\"Inference loop for a given model\"\"\"\n",
    "    \n",
    "    # Inference loop helpers\n",
    "    model = model.to(device)\n",
    "    predictions = weighted_prediction(config, n=weighted_frames)\n",
    "    start_time = time.time()\n",
    "    font = cv.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 1  # Font size\n",
    "    thickness = 2  # Font thickness\n",
    "    top_border_size = 20\n",
    "    border_color = (255, 255, 255)  # White color in BGR format\n",
    "    \n",
    "    # Create a named window\n",
    "    cv.namedWindow('Output', cv.WINDOW_NORMAL)\n",
    "\n",
    "    # Resize the window\n",
    "    window_width = 800\n",
    "    window_height = 600\n",
    "    cv.resizeWindow('Output', window_width, window_height)\n",
    "    \n",
    "    while True:\n",
    "        # Get frame\n",
    "        frame = get_frame(cam)\n",
    "        \n",
    "        # Transform image\n",
    "        frame = image_transformer(frame, size=image_size)\n",
    "       \n",
    "        # Transform to batch\n",
    "        frame = batch_image(frame)\n",
    "        frame = frame.to(device)\n",
    "       \n",
    "        # Predict\n",
    "        prediction = model(frame)\n",
    "\n",
    "        # Append prediction and print time\n",
    "        prediction_start_time = time.time()\n",
    "        out = predictions(prediction)\n",
    "        prediction_end_time = time.time()\n",
    "        print(f'Prediction time: {prediction_end_time - prediction_start_time}')\n",
    "        \n",
    "        # Image to numpy\n",
    "        frame = cv.cvtColor(frame.squeeze(0).detach().cpu().permute(1, 2, 0).numpy(), cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Add the border on top\n",
    "        frame = cv.copyMakeBorder(frame, top=top_border_size, bottom=0, left=0, right=0, \n",
    "                                              borderType=cv.BORDER_CONSTANT, value=border_color)\n",
    "        # Extract prediction\n",
    "        if out is not None:\n",
    "            text = predictions.map_labels(out)\n",
    "        else: \n",
    "            text = 'Out of scope'\n",
    "        \n",
    "        # Get text size\n",
    "        textsize = 10\n",
    "\n",
    "        # Position the text\n",
    "        print(textsize)\n",
    "        textX = (frame.shape[1] - textsize) // 2\n",
    "        textY = 30  # Position the text 30 pixels from the top edge\n",
    "        \n",
    "        # Put the text on the image\n",
    "        cv.putText(frame, text, (textX, textY), font, font_scale, (0,0,255), thickness)\n",
    "        \n",
    "        # Show image\n",
    "        cv.imshow('Output', frame)\n",
    "        \n",
    "        \n",
    "        # If total seconds have passed, break\n",
    "        if time.time() - start_time > total_seconds:\n",
    "            break\n",
    "        \n",
    "        # Wait for 25 ms and check if the user wants to exit (press 'q')\n",
    "        if cv.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 0.012494087219238281\n",
      "10\n",
      "Prediction time: 0.0035130977630615234\n",
      "10\n",
      "Prediction time: 0.00045418739318847656\n",
      "10\n",
      "Prediction time: 0.0008690357208251953\n",
      "10\n",
      "Prediction time: 0.000354766845703125\n",
      "10\n",
      "Prediction time: 0.00034308433532714844\n",
      "10\n",
      "Prediction time: 0.0003402233123779297\n",
      "10\n",
      "Prediction time: 0.00038909912109375\n",
      "10\n",
      "Prediction time: 0.00032782554626464844\n",
      "10\n",
      "Prediction time: 0.0004470348358154297\n",
      "10\n",
      "Prediction time: 0.0004019737243652344\n",
      "10\n",
      "Prediction time: 0.00045108795166015625\n",
      "10\n",
      "Prediction time: 0.00039315223693847656\n",
      "10\n",
      "Prediction time: 0.0004360675811767578\n",
      "10\n",
      "Prediction time: 0.0004069805145263672\n",
      "10\n",
      "Prediction time: 0.00040912628173828125\n",
      "10\n",
      "Prediction time: 0.00040340423583984375\n",
      "10\n",
      "Prediction time: 0.00043487548828125\n",
      "10\n",
      "Prediction time: 0.0004031658172607422\n",
      "10\n",
      "Prediction time: 0.0004780292510986328\n",
      "10\n",
      "Prediction time: 0.00044989585876464844\n",
      "10\n",
      "Prediction time: 0.00040602684020996094\n",
      "10\n",
      "Prediction time: 0.0004019737243652344\n",
      "10\n",
      "Prediction time: 0.00043129920959472656\n",
      "10\n",
      "Prediction time: 0.00043892860412597656\n",
      "10\n",
      "Prediction time: 0.0004181861877441406\n",
      "10\n",
      "Prediction time: 0.0003859996795654297\n",
      "10\n",
      "Prediction time: 0.00041294097900390625\n",
      "10\n",
      "Prediction time: 0.00047516822814941406\n",
      "10\n",
      "Prediction time: 0.0004181861877441406\n",
      "10\n",
      "Prediction time: 0.0004367828369140625\n",
      "10\n",
      "Prediction time: 0.0004558563232421875\n",
      "10\n",
      "Prediction time: 0.0004899501800537109\n",
      "10\n",
      "Prediction time: 0.0005619525909423828\n",
      "10\n",
      "Prediction time: 0.0004878044128417969\n",
      "10\n",
      "Prediction time: 0.0005021095275878906\n",
      "10\n",
      "Prediction time: 0.00039505958557128906\n",
      "10\n",
      "Prediction time: 0.00041484832763671875\n",
      "10\n",
      "Prediction time: 0.0004711151123046875\n",
      "10\n",
      "Prediction time: 0.000408172607421875\n",
      "10\n",
      "Prediction time: 0.00043392181396484375\n",
      "10\n",
      "Prediction time: 0.00042176246643066406\n",
      "10\n",
      "Prediction time: 0.00043582916259765625\n",
      "10\n",
      "Prediction time: 0.0005471706390380859\n",
      "10\n",
      "Prediction time: 0.00039696693420410156\n",
      "10\n",
      "Prediction time: 0.0004601478576660156\n",
      "10\n",
      "Prediction time: 0.000453948974609375\n",
      "10\n",
      "Prediction time: 0.00041174888610839844\n",
      "10\n",
      "Prediction time: 0.00047779083251953125\n",
      "10\n",
      "Prediction time: 0.00036907196044921875\n",
      "10\n",
      "Prediction time: 0.0004107952117919922\n",
      "10\n",
      "Prediction time: 0.0003981590270996094\n",
      "10\n",
      "Prediction time: 0.0004200935363769531\n",
      "10\n",
      "Prediction time: 0.0005381107330322266\n",
      "10\n",
      "Prediction time: 0.00040721893310546875\n",
      "10\n",
      "Prediction time: 0.0004820823669433594\n",
      "10\n",
      "Prediction time: 0.0004627704620361328\n",
      "10\n",
      "Prediction time: 0.00045680999755859375\n",
      "10\n",
      "Prediction time: 0.0003788471221923828\n",
      "10\n",
      "Prediction time: 0.0003840923309326172\n",
      "10\n",
      "Prediction time: 0.0004227161407470703\n",
      "10\n",
      "Prediction time: 0.00045108795166015625\n",
      "10\n",
      "Prediction time: 0.0003972053527832031\n",
      "10\n",
      "Prediction time: 0.0004279613494873047\n",
      "10\n",
      "Prediction time: 0.000392913818359375\n",
      "10\n",
      "Prediction time: 0.0004761219024658203\n",
      "10\n",
      "Prediction time: 0.0004191398620605469\n",
      "10\n",
      "Prediction time: 0.0004119873046875\n",
      "10\n",
      "Prediction time: 0.0004038810729980469\n",
      "10\n",
      "Prediction time: 0.0004930496215820312\n",
      "10\n",
      "Prediction time: 0.0005271434783935547\n",
      "10\n",
      "Prediction time: 0.0004112720489501953\n",
      "10\n",
      "Prediction time: 0.0004279613494873047\n",
      "10\n",
      "Prediction time: 0.0004029273986816406\n",
      "10\n",
      "Prediction time: 0.0004208087921142578\n",
      "10\n",
      "Prediction time: 0.0004508495330810547\n",
      "10\n",
      "Prediction time: 0.0004279613494873047\n",
      "10\n",
      "Prediction time: 0.0003440380096435547\n",
      "10\n",
      "Prediction time: 0.00041985511779785156\n",
      "10\n",
      "Prediction time: 0.0003910064697265625\n",
      "10\n",
      "Prediction time: 0.0004169940948486328\n",
      "10\n",
      "Prediction time: 0.00043320655822753906\n",
      "10\n",
      "Prediction time: 0.0004379749298095703\n",
      "10\n",
      "Prediction time: 0.0004029273986816406\n",
      "10\n",
      "Prediction time: 0.0004737377166748047\n",
      "10\n",
      "Prediction time: 0.0004858970642089844\n",
      "10\n",
      "Prediction time: 0.00041985511779785156\n",
      "10\n",
      "Prediction time: 0.00036597251892089844\n",
      "10\n",
      "Prediction time: 0.0004360675811767578\n",
      "10\n",
      "Prediction time: 0.0004379749298095703\n",
      "10\n",
      "Prediction time: 0.0004470348358154297\n",
      "10\n",
      "Prediction time: 0.0004608631134033203\n",
      "10\n",
      "Prediction time: 0.00041794776916503906\n",
      "10\n",
      "Prediction time: 0.0004200935363769531\n",
      "10\n",
      "Prediction time: 0.0004649162292480469\n",
      "10\n",
      "Prediction time: 0.00037670135498046875\n",
      "10\n",
      "Prediction time: 0.0005071163177490234\n",
      "10\n",
      "Prediction time: 0.00043392181396484375\n",
      "10\n",
      "Prediction time: 0.00045680999755859375\n",
      "10\n",
      "Prediction time: 0.0004169940948486328\n",
      "10\n",
      "Prediction time: 0.0004680156707763672\n",
      "10\n",
      "Prediction time: 0.0004329681396484375\n",
      "10\n",
      "Prediction time: 0.0004391670227050781\n",
      "10\n",
      "Prediction time: 0.00041413307189941406\n",
      "10\n",
      "Prediction time: 0.0004258155822753906\n",
      "10\n",
      "Prediction time: 0.00045990943908691406\n",
      "10\n",
      "Prediction time: 0.0005042552947998047\n",
      "10\n",
      "Prediction time: 0.00047397613525390625\n",
      "10\n",
      "Prediction time: 0.0003840923309326172\n",
      "10\n",
      "Prediction time: 0.0004558563232421875\n",
      "10\n",
      "Prediction time: 0.0004379749298095703\n",
      "10\n",
      "Prediction time: 0.0004909038543701172\n",
      "10\n",
      "Prediction time: 0.00044727325439453125\n",
      "10\n",
      "Prediction time: 0.00042819976806640625\n",
      "10\n",
      "Prediction time: 0.0003597736358642578\n",
      "10\n",
      "Prediction time: 0.00044226646423339844\n",
      "10\n",
      "Prediction time: 0.0003998279571533203\n",
      "10\n",
      "Prediction time: 0.0004222393035888672\n",
      "10\n",
      "Prediction time: 0.0009012222290039062\n",
      "10\n",
      "Prediction time: 0.00041294097900390625\n",
      "10\n",
      "Prediction time: 0.00042510032653808594\n",
      "10\n",
      "Prediction time: 0.000431060791015625\n",
      "10\n",
      "Prediction time: 0.0004169940948486328\n",
      "10\n",
      "Prediction time: 0.0003898143768310547\n",
      "10\n",
      "Prediction time: 0.0004241466522216797\n",
      "10\n",
      "Prediction time: 0.0003650188446044922\n",
      "10\n",
      "Prediction time: 0.00033926963806152344\n",
      "10\n",
      "Prediction time: 0.0004837512969970703\n",
      "10\n",
      "Prediction time: 0.0004000663757324219\n",
      "10\n",
      "Prediction time: 0.0007848739624023438\n",
      "10\n",
      "Prediction time: 0.0006210803985595703\n",
      "10\n",
      "Prediction time: 0.0005199909210205078\n",
      "10\n",
      "Prediction time: 0.0004448890686035156\n",
      "10\n",
      "Prediction time: 0.0005478858947753906\n",
      "10\n",
      "Prediction time: 0.0004999637603759766\n",
      "10\n",
      "Prediction time: 0.0004677772521972656\n",
      "10\n",
      "Prediction time: 0.0004611015319824219\n",
      "10\n",
      "Prediction time: 0.0004112720489501953\n",
      "10\n",
      "Prediction time: 0.00042700767517089844\n",
      "10\n",
      "Prediction time: 0.0004413127899169922\n",
      "10\n",
      "Prediction time: 0.00045180320739746094\n",
      "10\n",
      "Prediction time: 0.0004069805145263672\n",
      "10\n",
      "Prediction time: 0.0004730224609375\n",
      "10\n",
      "Prediction time: 0.0004260540008544922\n",
      "10\n",
      "Prediction time: 0.00040221214294433594\n",
      "10\n",
      "Prediction time: 0.0004558563232421875\n",
      "10\n",
      "Prediction time: 0.00045228004455566406\n",
      "10\n",
      "Prediction time: 0.00045013427734375\n",
      "10\n",
      "Prediction time: 0.0004773139953613281\n",
      "10\n",
      "Prediction time: 0.0004291534423828125\n",
      "10\n",
      "Prediction time: 0.0004487037658691406\n",
      "10\n",
      "Prediction time: 0.00046706199645996094\n",
      "10\n",
      "Prediction time: 0.0004038810729980469\n",
      "10\n",
      "Prediction time: 0.0004811286926269531\n",
      "10\n",
      "Prediction time: 0.0004241466522216797\n",
      "10\n",
      "Prediction time: 0.0005540847778320312\n",
      "10\n",
      "Prediction time: 0.00041222572326660156\n",
      "10\n",
      "Prediction time: 0.0005669593811035156\n",
      "10\n",
      "Prediction time: 0.00043392181396484375\n",
      "10\n",
      "Prediction time: 0.0004069805145263672\n",
      "10\n",
      "Prediction time: 0.0004200935363769531\n",
      "10\n",
      "Prediction time: 0.0004208087921142578\n",
      "10\n",
      "Prediction time: 0.0004248619079589844\n",
      "10\n",
      "Prediction time: 0.0004870891571044922\n",
      "10\n",
      "Prediction time: 0.0005221366882324219\n",
      "10\n",
      "Prediction time: 0.00043702125549316406\n",
      "10\n",
      "Prediction time: 0.0004420280456542969\n",
      "10\n",
      "Prediction time: 0.0004858970642089844\n",
      "10\n",
      "Prediction time: 0.0004799365997314453\n",
      "10\n",
      "Prediction time: 0.0005419254302978516\n",
      "10\n",
      "Prediction time: 0.00040602684020996094\n",
      "10\n",
      "Prediction time: 0.0005691051483154297\n",
      "10\n",
      "Prediction time: 0.000507354736328125\n",
      "10\n",
      "Prediction time: 0.0004849433898925781\n",
      "10\n",
      "Prediction time: 0.0004930496215820312\n",
      "10\n",
      "Prediction time: 0.0005030632019042969\n",
      "10\n",
      "Prediction time: 0.0004489421844482422\n",
      "10\n",
      "Prediction time: 0.0004181861877441406\n",
      "10\n",
      "Prediction time: 0.00045800209045410156\n",
      "10\n",
      "Prediction time: 0.00045609474182128906\n",
      "10\n",
      "Prediction time: 0.0004520416259765625\n",
      "10\n",
      "Prediction time: 0.00044798851013183594\n",
      "10\n",
      "Prediction time: 0.00041604042053222656\n",
      "10\n",
      "Prediction time: 0.0005340576171875\n",
      "10\n",
      "Prediction time: 0.00043511390686035156\n",
      "10\n",
      "Prediction time: 0.0004248619079589844\n",
      "10\n",
      "Prediction time: 0.0004220008850097656\n",
      "10\n",
      "Prediction time: 0.0004329681396484375\n",
      "10\n",
      "Prediction time: 0.000453948974609375\n",
      "10\n",
      "Prediction time: 0.0004258155822753906\n",
      "10\n",
      "Prediction time: 0.0004191398620605469\n",
      "10\n",
      "Prediction time: 0.00046896934509277344\n",
      "10\n",
      "Prediction time: 0.0003972053527832031\n",
      "10\n",
      "Prediction time: 0.0004038810729980469\n",
      "10\n",
      "Prediction time: 0.00044727325439453125\n",
      "10\n",
      "Prediction time: 0.0004961490631103516\n",
      "10\n",
      "Prediction time: 0.0004658699035644531\n",
      "10\n",
      "Prediction time: 0.000408172607421875\n",
      "10\n",
      "Prediction time: 0.00042510032653808594\n",
      "10\n",
      "Prediction time: 0.0005049705505371094\n",
      "10\n",
      "Prediction time: 0.0004818439483642578\n",
      "10\n",
      "Prediction time: 0.0005860328674316406\n",
      "10\n",
      "Prediction time: 0.0009539127349853516\n",
      "10\n",
      "Prediction time: 0.0005660057067871094\n",
      "10\n",
      "Prediction time: 0.0005507469177246094\n",
      "10\n",
      "Prediction time: 0.0006031990051269531\n",
      "10\n",
      "Prediction time: 0.0004868507385253906\n",
      "10\n",
      "Prediction time: 0.0004947185516357422\n",
      "10\n",
      "Prediction time: 0.0004608631134033203\n",
      "10\n",
      "Prediction time: 0.0004680156707763672\n",
      "10\n",
      "Prediction time: 0.0005772113800048828\n",
      "10\n",
      "Prediction time: 0.0005941390991210938\n",
      "10\n",
      "Prediction time: 0.0004107952117919922\n",
      "10\n",
      "Prediction time: 0.0004239082336425781\n",
      "10\n",
      "Prediction time: 0.0004298686981201172\n",
      "10\n",
      "Prediction time: 0.00039196014404296875\n",
      "10\n",
      "Prediction time: 0.0004558563232421875\n",
      "10\n",
      "Prediction time: 0.0004169940948486328\n",
      "10\n",
      "Prediction time: 0.0004570484161376953\n",
      "10\n",
      "Prediction time: 0.00040078163146972656\n",
      "10\n",
      "Prediction time: 0.00043082237243652344\n",
      "10\n",
      "Prediction time: 0.000415802001953125\n",
      "10\n",
      "Prediction time: 0.0005712509155273438\n",
      "10\n",
      "Prediction time: 0.0004601478576660156\n",
      "10\n",
      "Prediction time: 0.0004069805145263672\n",
      "10\n",
      "Prediction time: 0.0005562305450439453\n",
      "10\n",
      "Prediction time: 0.00040078163146972656\n",
      "10\n",
      "Prediction time: 0.0009090900421142578\n",
      "10\n",
      "Prediction time: 0.0004169940948486328\n",
      "10\n",
      "Prediction time: 0.00041604042053222656\n",
      "10\n",
      "Prediction time: 0.00038504600524902344\n",
      "10\n",
      "Prediction time: 0.0003902912139892578\n",
      "10\n",
      "Prediction time: 0.0004620552062988281\n",
      "10\n",
      "Prediction time: 0.0004048347473144531\n",
      "10\n",
      "Prediction time: 0.0004029273986816406\n",
      "10\n",
      "Prediction time: 0.0004260540008544922\n",
      "10\n",
      "Prediction time: 0.0004100799560546875\n",
      "10\n",
      "Prediction time: 0.0004448890686035156\n",
      "10\n",
      "Prediction time: 0.00045800209045410156\n",
      "10\n",
      "Prediction time: 0.0004260540008544922\n",
      "10\n",
      "Prediction time: 0.00040912628173828125\n",
      "10\n",
      "Prediction time: 0.0004076957702636719\n",
      "10\n",
      "Prediction time: 0.00041031837463378906\n",
      "10\n",
      "Prediction time: 0.00041794776916503906\n",
      "10\n",
      "Prediction time: 0.0004620552062988281\n",
      "10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m inference_predictions \u001b[38;5;241m=\u001b[39m inference_loop(efficient, image_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL_SQUARED\u001b[39m\u001b[38;5;124m'\u001b[39m, weighted_frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, total_seconds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 38\u001b[0m, in \u001b[0;36minference_loop\u001b[0;34m(model, image_size, weighted_frames, total_seconds, device)\u001b[0m\n\u001b[1;32m     35\u001b[0m frame \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model(frame)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Append prediction and print time\u001b[39;00m\n\u001b[1;32m     41\u001b[0m prediction_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/School/semester_3/advanced_ml/aml_itu/utils/models/EfficientNet.py:146\u001b[0m, in \u001b[0;36mEfficientNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 146\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures(x)\n\u001b[1;32m    147\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m    148\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/School/semester_3/advanced_ml/aml_itu/utils/models/EfficientNet.py:115\u001b[0m, in \u001b[0;36mMBConvN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    113\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpand(x)\n\u001b[1;32m    114\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepthwise_conv(x)\n\u001b[0;32m--> 115\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mse(x)\n\u001b[1;32m    116\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpointwise_conv(x)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_connection:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/School/semester_3/advanced_ml/aml_itu/utils/models/EfficientNet.py:53\u001b[0m, in \u001b[0;36mSqueezeExcitation.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 53\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mse(x)\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m*\u001b[39m y\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py:393\u001b[0m, in \u001b[0;36mSiLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39msilu(\u001b[38;5;28minput\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minplace)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/functional.py:2074\u001b[0m, in \u001b[0;36msilu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   2072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   2073\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39msilu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 2074\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39msilu(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inference_predictions = inference_loop(efficient, image_size='L_SQUARED', weighted_frames=10, total_seconds=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
