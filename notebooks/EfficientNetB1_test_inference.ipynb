{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device found.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import timm\n",
    "import torch\n",
    "import time\n",
    "import torch\n",
    "import psutil\n",
    "from torch import nn\n",
    "import torchvision\n",
    "torchvision.disable_beta_transforms_warning()\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "os.environ[\"COLAB\"] = \"False\"\n",
    "# Changing directory into aml_itu\n",
    "if os.getcwd().split('/')[-1] != 'aml_itu': os.chdir(os.path.abspath('.').split('aml_itu/')[0]+'aml_itu')\n",
    "\n",
    "from utils.helpers import *\n",
    "from utils.StatefarmPytorchDataset import StateFarmDataset\n",
    "\n",
    "# Setting up device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print (f\"GPU is available\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print('MPS device found.')\n",
    "else:\n",
    "    print (\"No GPU available, using CPU instead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {'name': 'state-farm-distracted-driver-detection',\n",
       "  'colab_path': '/content/drive/MyDrive/aml-distracted-drivers-project',\n",
       "  'data': '../state-farm-distracted-driver-detection/driver_imgs_list.csv',\n",
       "  'images': {'train': '../state-farm-distracted-driver-detection/imgs/train',\n",
       "   'test': '../state-farm-distracted-driver-detection/imgs/test'},\n",
       "  'class_mapping': {'c0': 'safe driving',\n",
       "   'c1': 'texting - right',\n",
       "   'c2': 'talking on the phone - right',\n",
       "   'c3': 'texting - left',\n",
       "   'c4': 'talking on the phone - left',\n",
       "   'c5': 'operating the radio',\n",
       "   'c6': 'drinking',\n",
       "   'c7': 'reaching behind',\n",
       "   'c8': 'hair and makeup',\n",
       "   'c9': 'talking to passenger'}},\n",
       " 'outputs': {'path': './outputs'},\n",
       " 'modeling_params': {'batch_size': 32, 'epochs': 100}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = 'EfficientNet-b1_90acc'\n",
    "\n",
    "# Loading the config file (if content is in workin directory must mean colab is being used)\n",
    "config = load_config(eval(os.environ[\"COLAB\"]))\n",
    "\n",
    "# Training Images\n",
    "train_img = config['dataset']['images']['train']\n",
    "\n",
    "# Outputting config\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, device):\n",
    "    \"\"\"Test loop\"\"\"\n",
    "    # Setup test accuracy\n",
    "    test_acc = 0\n",
    "    \n",
    "    images = []\n",
    "    classes = []\n",
    "    predictions = []\n",
    "    predictions_argmax = []\n",
    "    \n",
    "    # Disable gradient calculations\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloader):   \n",
    "            # Extract imgs and labels and sent to device\n",
    "            imgs, labels = data\n",
    "            images.append(imgs), classes.append(labels)\n",
    "            \n",
    "            imgs, labels  = imgs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            prediction = model(imgs)\n",
    "            predictions.append(prediction)\n",
    "            predictions_argmax.append(prediction.argmax(1))\n",
    "\n",
    "            # Update test accuracy\n",
    "            test_acc += (prediction.argmax(1) == labels).type(torch.float).mean().item()\n",
    "    # Return test accuracy\n",
    "    print(f'Test Accuracy {test_acc / len(dataloader)}')\n",
    "    return images, classes, predictions, predictions_argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Setup\n",
    "model_name = 'efficientnet_b1'\n",
    "model = timm.create_model(model_name, pretrained=True)\n",
    "num_ftrs = model.classifier.in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.7),\n",
    "    nn.Linear(num_ftrs, 10)\n",
    ")\n",
    "\n",
    "# Load the saved model weights\n",
    "model_load_path = 'outputs/EfficientNet/best_model_epoch_3.pth'\n",
    "model.load_state_dict(torch.load(model_load_path, map_location=torch.device('mps')))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of test data: 3433\n"
     ]
    }
   ],
   "source": [
    "# IMG Transformations\n",
    "augmentations = {\n",
    "    'train': v2.Compose([\n",
    "    # v2.RandomRotation(degrees=30),\n",
    "    v2.RandomResizedCrop((168, 224), antialias=True, scale=(0.9, 1)),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ToDtype(torch.float32, scale=True)]),\n",
    "    'val+test': v2.Compose([\n",
    "    T.Resize((168, 224), antialias=True),\n",
    "    v2.ToDtype(torch.float32, scale=True)])}\n",
    "\n",
    "# Target Transformations (Removing the c from the target)\n",
    "target_transform = T.Lambda(lambda y: torch.tensor(int(y.replace('c', ''))))\n",
    "\n",
    "test_data = StateFarmDataset(config, \n",
    "                            split='test', \n",
    "                            transform=augmentations['val+test'], \n",
    "                            target_transform=target_transform)\n",
    "\n",
    "print(f'Lenght of test data: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_data, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 0.8939599483512168\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "t = test(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 0.8942\n",
      "Average Inference Time per Batch: 0.1153 seconds\n"
     ]
    }
   ],
   "source": [
    "def test_inference_time(model, dataloader, device):\n",
    "    test_acc = 0\n",
    "    total_time = 0\n",
    "\n",
    "    # Function to print memory usage\n",
    "    def print_memory_usage():\n",
    "        process = psutil.Process()\n",
    "        memory_info = process.memory_info()\n",
    "        print(f\"Memory Usage: {memory_info.rss / (1024 * 1024)} MB\")  # Convert bytes to MB\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloader):   \n",
    "            imgs, labels = data\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "            # Print memory usage before inference\n",
    "            #print(\"Before Inference:\")\n",
    "            #print_memory_usage()\n",
    "\n",
    "            start_time = time.time()  # Start time\n",
    "            prediction = model(imgs)\n",
    "            end_time = time.time()  # End time\n",
    "\n",
    "            # Print memory usage after inference\n",
    "            #print(\"After Inference:\")\n",
    "            #print_memory_usage()\n",
    "\n",
    "            total_time += (end_time - start_time)  # Add to total time\n",
    "            test_acc += (prediction.argmax(1) == labels).type(torch.float).mean().item()\n",
    "\n",
    "    avg_inference_time = round(total_time / len(dataloader), 4)\n",
    "\n",
    "    test_acc = round(test_acc / len(dataloader), 4)\n",
    "    print(f'Test Accuracy {test_acc}')\n",
    "    print(f'Average Inference Time per Batch: {avg_inference_time} seconds')\n",
    "\n",
    "#test model\n",
    "model.eval()\n",
    "test_inference_time(model, test_dataloader, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basicenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
