{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmGPfIwRKzFV"
      },
      "source": [
        "# `Setup`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceRf-vSlKzFW",
        "outputId": "cbba2297-3b61-4901-969c-5a663fd2f7e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From https://github.com/RasKrebs/aml_itu\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n",
            "MPS device found.\n",
            "/Users/alexanderries/aml_itu\n",
            "MPS device found.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import datetime as dt\n",
        "from math import ceil\n",
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "try:\n",
        "    # Mounting Colab Drive if possible\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Cloning repo for colab\n",
        "    if 'aml_itu' in os.getcwd():\n",
        "        %cd aml_itu/\n",
        "        !git pull https://github.com/RasKrebs/aml_itu\n",
        "        !git checkout -b sparse_filtering\n",
        "    else:\n",
        "        !git clone -b sparse_test https://github.com/RasKrebs/aml_itu\n",
        "        %cd aml_itu/\n",
        "    os.environ[\"COLAB\"] = \"True\"\n",
        "\n",
        "except:\n",
        "    # Changing directory into aml_itu\n",
        "    if os.getcwd().split('/')[-1] != 'aml_itu': os.chdir(os.path.abspath('.').split('aml_itu/')[0]+'aml_itu')\n",
        "    !git pull origin main --ff-only\n",
        "    os.environ[\"COLAB\"] = \"False\"\n",
        "\n",
        "# Utils Import\n",
        "from utils.helpers import *\n",
        "from utils.StatefarmPytorchDataset import StateFarmDataset\n",
        "\n",
        "\n",
        "# Torch\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "torchvision.disable_beta_transforms_warning()\n",
        "import torchvision.transforms as T\n",
        "from torchvision.transforms import v2\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Install torchinfo, import if it's available\n",
        "try:\n",
        "  import torchinfo\n",
        "except:\n",
        "  !pip install torchinfo\n",
        "  import torchinfo\n",
        "\n",
        "from torchinfo import summary\n",
        "\n",
        "\n",
        "# Printing current working directory\n",
        "print(os.getcwd())\n",
        "\n",
        "# Setting up device\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print (f\"GPU is available\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "    print('MPS device found.')\n",
        "else:\n",
        "    print (\"No GPU available, using CPU instead\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qujmd-H5KzFX"
      },
      "source": [
        "### `Config`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fR4A88qzKzFX"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dataset': {'name': 'state-farm-distracted-driver-detection',\n",
              "  'colab_path': '/content/drive/MyDrive/aml-distracted-drivers-project',\n",
              "  'data': '../state-farm-distracted-driver-detection/driver_imgs_list.csv',\n",
              "  'images': {'train': '../state-farm-distracted-driver-detection/imgs/train',\n",
              "   'test': '../state-farm-distracted-driver-detection/imgs/test'},\n",
              "  'class_mapping': {'c0': 'safe driving',\n",
              "   'c1': 'texting - right',\n",
              "   'c2': 'talking on the phone - right',\n",
              "   'c3': 'texting - left',\n",
              "   'c4': 'talking on the phone - left',\n",
              "   'c5': 'operating the radio',\n",
              "   'c6': 'drinking',\n",
              "   'c7': 'reaching behind',\n",
              "   'c8': 'hair and makeup',\n",
              "   'c9': 'talking to passenger'}},\n",
              " 'outputs': {'path': './outputs'},\n",
              " 'modeling_params': {'batch_size': 32, 'epochs': 100}}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MODEL_NAME = 'TinyVGG_best'\n",
        "\n",
        "# Loading the config file (if content is in workin directory must mean colab is being used)\n",
        "config = load_config(eval(os.environ[\"COLAB\"]))\n",
        "\n",
        "\n",
        "# Training Images\n",
        "train_img = config['dataset']['images']['train']\n",
        "\n",
        "# Outputting config\n",
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "m3ABOz6Ol0Zl"
      },
      "outputs": [],
      "source": [
        "def save_model(model, model_name, epoch):\n",
        "    \"\"\"Function for saving model\"\"\"\n",
        "    # Model name, with path\n",
        "    timestamp = dt.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    file = f'{model_name}_{timestamp}_epoch_{epoch+1}'\n",
        "    name = os.path.join(config['outputs']['path'], model_name, file)\n",
        "\n",
        "    # Make directory if not exists\n",
        "    if not os.path.exists(os.path.join(os.path.join(config['outputs']['path'], model_name))):\n",
        "        os.makedirs(os.path.join(os.path.join(config['outputs']['path'], model_name)))\n",
        "\n",
        "    # Save model\n",
        "    torch.save(model.state_dict(), f'{name}.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RKyqh-awZCv"
      },
      "source": [
        "## Sparse Filtring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2prAFACAwZCv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import gc\n",
        "gc.collect()\n",
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "from torch.utils.data import Subset\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import random\n",
        "from torch.utils.data import Subset\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import random\n",
        "\n",
        "# Sparse Filter Class\n",
        "class SparseFilter(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(SparseFilter, self).__init__()\n",
        "        self.weights = nn.Parameter(torch.randn(input_dim, output_dim) * 0.5)\n",
        "        self.epsilon = 1e-8\n",
        "\n",
        "    def soft_abs(self, value):\n",
        "        return torch.sqrt(value ** 2 + self.epsilon)\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(x.shape)\n",
        "        print(self.weights.shape)\n",
        "        first = torch.matmul(x, self.weights)\n",
        "        second = self.soft_abs(first)\n",
        "        third = second / torch.sqrt(torch.sum(second ** 2, axis=0) + self.epsilon)\n",
        "        fourth = third / torch.sqrt(torch.sum(third ** 2, axis=1)[:, None] + self.epsilon)\n",
        "        return torch.sum(fourth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "v3_transform = v2.Compose([\n",
        "    v2.ToPILImage(),\n",
        "    v2.ToDtype(torch.float32, scale=True),  \n",
        "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    torch.flatten\n",
        "    ])\n",
        "\n",
        "# Load the dataset without transformations\n",
        "train_data = StateFarmDataset(config,\n",
        "                              transform=v3_transform,  # Transformations\n",
        "                              split='train',\n",
        "                              target_transform=None)\n",
        "\n",
        "# Generate random indices for the subset\n",
        "subset_size = 1000\n",
        "indices = torch.randperm(len(train_data)).tolist()\n",
        "subset_indices = indices[:subset_size]\n",
        "\n",
        "# Create a subset\n",
        "train_subset = Subset(train_data, subset_indices)\n",
        "\n",
        "# Create a DataLoader for the subset\n",
        "train_subset_loader = DataLoader(train_data, batch_size=8, num_workers=4, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RvX-JJI9jCpr"
      },
      "outputs": [],
      "source": [
        "def train_step(model, dataloader, optimizer, device, accumulation_steps=4):\n",
        "    \"\"\"Train step for a single epoch with gradient accumulation.\"\"\"\n",
        "\n",
        "    # Losses and accuracies\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    # Initialize the gradient\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for i, data in enumerate(dataloader):\n",
        "\n",
        "        # Extracting data and labels + moving to device\n",
        "        imgs, labels = data\n",
        "        imgs = imgs.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        loss = model(imgs)\n",
        "\n",
        "        # Normalize the loss to account for accumulation\n",
        "        normalized_loss = loss / accumulation_steps\n",
        "\n",
        "        # Backward pass (accumulates gradients over multiple backward steps)\n",
        "        normalized_loss.backward()\n",
        "\n",
        "        # Step with optimizer every 'accumulation_steps' iterations\n",
        "        if (i + 1) % accumulation_steps == 0 or (i + 1) == len(dataloader):\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        # Update train loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Return average train loss\n",
        "    return train_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_training(history, num_epochs=50):\n",
        "\n",
        "    # Generate Figure\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    # Loss Plots\n",
        "    sns.lineplot(y=history['train_loss'], x=list(range(len(history['train_loss']))), ax=axs[0], label='Train Loss')\n",
        "    sns.lineplot(y=history['val_loss'], x=list(range(len(history['val_loss']))), ax=axs[0], label='Validation Loss')\n",
        "    axs[0].set_ylabel('Cross Entropy Loss')\n",
        "    axs[0].set_xlabel('Epochs')\n",
        "    axs[0].set_xlim(0, num_epochs)\n",
        "\n",
        "    # Accuracy Plots\n",
        "    sns.lineplot(y=history['train_acc'], x=list(range(len(history['train_acc']))), ax=axs[1], label='Train Accuracy')\n",
        "    sns.lineplot(y=history['val_acc'], x=list(range(len(history['val_acc']))), ax=axs[1], label='Validation Accuracy')\n",
        "    axs[1].set_ylabel('Accuracy')\n",
        "    axs[1].set_xlabel('Epochs')\n",
        "    axs[1].set_xlim(0, num_epochs)\n",
        "\n",
        "    # Show plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8e9GmdtYjR_i"
      },
      "outputs": [],
      "source": [
        "def train_sparse_filter(model, train_dataloader, optimizer, epochs, device):\n",
        "    \"\"\"Model training method\"\"\"\n",
        "    # History\n",
        "    history = dict(train_loss=[],\n",
        "                   train_acc=[],\n",
        "                   val_loss=[],\n",
        "                   val_acc=[])\n",
        "\n",
        "    # Loop through epochs\n",
        "    for epoch in range(epochs):\n",
        "        print(f'\\nEpoch {epoch+1} of {epochs} started...')\n",
        "\n",
        "        # Set model to train mode and do pass over data\n",
        "        model.train(True)\n",
        "        train_loss = train_step(model, train_dataloader, optimizer, device)\n",
        "\n",
        "        print(f\"Epoch {epoch+1} of {epochs} - Train loss: {train_loss:.5f}\")\n",
        "\n",
        "        # Save model\n",
        "        save_model(model, MODEL_NAME, epoch)\n",
        "\n",
        "        # Save train and val loss/acc\n",
        "        history['train_loss'].append(train_loss)\n",
        "\n",
        "        # Visualize every 5th epoch\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            visualize_training(history, epochs)\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "od6JKwpTjrVc"
      },
      "outputs": [],
      "source": [
        "# Define and train the sparse filter model\n",
        "input_dim = 3*480*640  # Input dimension\n",
        "output_dim = 3*48*64  # Desired output dimension\n",
        "sparse_filter_model1 = SparseFilter(input_dim, output_dim).to(device)  # Move model to GPU\n",
        "learning_rate = 0.01\n",
        "optimizer = optim.Adam(sparse_filter_model1.parameters(), lr=learning_rate)\n",
        "epochs = 50\n",
        "\n",
        "\n",
        "\n",
        "results = train_sparse_filter(model=sparse_filter_model1,\n",
        "                train_dataloader=train_subset_loader,\n",
        "                optimizer=optimizer,\n",
        "                epochs=epochs,\n",
        "                device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqpxHyB2wZCw"
      },
      "outputs": [],
      "source": [
        "# Save the model weights\n",
        "torch.save(sparse_filter_model1.state_dict(), './outputs/SparseFilterWeights/sparse_filter_model_try2.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TCpNU2IoMd6"
      },
      "outputs": [],
      "source": [
        "\n",
        "torch.save(sparse_filter_model1.state_dict(), './drive/MyDrive')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "3c8ad80dbc202ee9aff426fa151d52828bd7b4f3aec4c0ec93048b40e8792c84"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
