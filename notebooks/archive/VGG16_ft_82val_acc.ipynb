{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmGPfIwRKzFV"
      },
      "source": [
        "# `Setup`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceRf-vSlKzFW",
        "outputId": "f0388aa0-7ed4-4198-fab2-626246eae361"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From https://github.com/RasKrebs/aml_itu\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n",
            "/Users/alexanderries/aml_itu\n",
            "MPS device found.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "import datetime as dt\n",
        "from math import ceil\n",
        "try:\n",
        "    # Mounting Colab Drive if possible\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Cloning repo for colab\n",
        "    if 'aml_itu' in os.getcwd():\n",
        "        %cd aml_itu/\n",
        "        !git pull https://github.com/RasKrebs/aml_itu\n",
        "    else:\n",
        "        !git clone https://github.com/RasKrebs/aml_itu\n",
        "        %cd aml_itu/\n",
        "    os.environ[\"COLAB\"] = \"True\"\n",
        "\n",
        "except:\n",
        "    # Changing directory into aml_itu\n",
        "    if os.getcwd().split('/')[-1] != 'aml_itu': os.chdir(os.path.abspath('.').split('aml_itu/')[0]+'aml_itu')\n",
        "    !git pull origin main --ff-only\n",
        "    os.environ[\"COLAB\"] = \"False\"\n",
        "\n",
        "# Utils Import\n",
        "from utils.helpers import *\n",
        "from utils.StatefarmPytorchDataset import StateFarmDataset\n",
        "\n",
        "# Torch\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from torchvision.transforms import v2\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "import math\n",
        "\n",
        "\n",
        "# Install torchinfo, import if it's available\n",
        "try:\n",
        "  import torchinfo\n",
        "except:\n",
        "  !pip install torchinfo\n",
        "  import torchinfo\n",
        "\n",
        "from torchinfo import summary\n",
        "\n",
        "\n",
        "# Printing current working directory\n",
        "print(os.getcwd())\n",
        "\n",
        "# Setting up device\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print (f\"GPU is available\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "    print('MPS device found.')\n",
        "else:\n",
        "    print (\"No GPU available, using CPU instead\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import packages\n",
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision import models, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# setting random number seed. Arbitrary seed is OK.\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qujmd-H5KzFX"
      },
      "source": [
        "### `Config`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR4A88qzKzFX",
        "outputId": "bf171fda-ed9b-42f4-a24a-2a2f83150932"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dataset': {'name': 'state-farm-distracted-driver-detection',\n",
              "  'colab_path': '/content/drive/MyDrive/aml-distracted-drivers-project',\n",
              "  'data': '../state-farm-distracted-driver-detection/driver_imgs_list.csv',\n",
              "  'images': {'train': '../state-farm-distracted-driver-detection/imgs/train',\n",
              "   'test': '../state-farm-distracted-driver-detection/imgs/test'},\n",
              "  'class_mapping': {'c0': 'safe driving',\n",
              "   'c1': 'texting - right',\n",
              "   'c2': 'talking on the phone - right',\n",
              "   'c3': 'texting - left',\n",
              "   'c4': 'talking on the phone - left',\n",
              "   'c5': 'operating the radio',\n",
              "   'c6': 'drinking',\n",
              "   'c7': 'reaching behind',\n",
              "   'c8': 'hair and makeup',\n",
              "   'c9': 'talking to passenger'}},\n",
              " 'outputs': {'path': './outputs'},\n",
              " 'modeling_params': {'batch_size': 32, 'epochs': 100}}"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Loading the config file (if content is in workin directory must mean colab is being used)\n",
        "config = load_config(eval(os.environ[\"COLAB\"]))\n",
        "\n",
        "# Training Images\n",
        "train_img = config['dataset']['images']['train']\n",
        "\n",
        "# Outputting config\n",
        "config"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tDaRwhJjKzFY"
      },
      "source": [
        "## `Finetuned Models`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "9T9mX5BKKzFY"
      },
      "outputs": [],
      "source": [
        "# IMG Transformations\n",
        "transforms = {\n",
        "    'train': v2.Compose([\n",
        "    v2.RandomRotation(degrees=30),\n",
        "    v2.RandomResizedCrop(size=224, antialias=True, scale=(0.9, 1)),\n",
        "    v2.RandomHorizontalFlip(p=0.5),\n",
        "    v2.ToDtype(torch.float32, scale=True)]),\n",
        "    'val': v2.Compose([\n",
        "    v2.RandomResizedCrop(size=224, antialias=True, scale=(0.9, 1)),\n",
        "    v2.ToDtype(torch.float32, scale=True)])}\n",
        "\n",
        "\n",
        "\n",
        "# Target Transformations (Removing the c from the target)\n",
        "target_transform = T.Lambda(lambda y: torch.tensor(int(y.replace('c', ''))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "QXckhcO8KzFX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lenght of train data: 14409\n",
            "Lenght of val data: 3345\n",
            "Lenght of val data: 4670\n"
          ]
        }
      ],
      "source": [
        "# Normal Dataset\n",
        "# Creating the dataset\n",
        "train_data = StateFarmDataset(config, \n",
        "                              transform=transforms['train'], \n",
        "                              split='train', \n",
        "                              target_transform=target_transform)\n",
        "\n",
        "print(f'Lenght of train data: {len(train_data)}')\n",
        "\n",
        "# Creating the dataset\n",
        "val_data = StateFarmDataset(config, \n",
        "                            transform=transforms['val'], \n",
        "                            split='val', \n",
        "                            target_transform=target_transform)\n",
        "\n",
        "print(f'Lenght of val data: {len(val_data)}')\n",
        "\n",
        "test_data = StateFarmDataset(config, \n",
        "                            split='test', \n",
        "                            transform=transforms['val'], \n",
        "                            target_transform=target_transform)\n",
        "\n",
        "print(f'Lenght of val data: {len(test_data)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create subsets of the train_data and val_data\n",
        "#train_data = torch.utils.data.Subset(train_data, range(0, 1000))\n",
        "#val_data = torch.utils.data.Subset(val_data, range(0, 1000))\n",
        "\n",
        "\n",
        "# Create dataloaders dict with subsets of the data\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "dataloaders = {\n",
        "    'train': DataLoader(train_data, batch_size=batch_size, shuffle=True),\n",
        "    'val': DataLoader(val_data, batch_size=batch_size, shuffle=True),\n",
        "    'test': DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Displaying training data including transformations\n",
        "#train_data.display_classes(id_to_class=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOlK-farQYyk"
      },
      "source": [
        "#### `Model`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/alexanderries/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/Users/alexanderries/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load pretrained vgg16 from PyTorch as an instance\n",
        "# need to make setting 'internet' to 'On'.\n",
        "use_pretrained = True\n",
        "net = models.vgg16(pretrained=use_pretrained)\n",
        "\n",
        "# Replace output layer for 2 class classifier, 'NORMAL' and 'PNEUMONIA'.\n",
        "net.classifier[6] = nn.Linear(in_features=4096, out_features=10)\n",
        "\n",
        "net.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "TUxzvRBVQYyk"
      },
      "outputs": [],
      "source": [
        "# setting of loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# setting fine tuned parameters\n",
        "\n",
        "params_to_update_1 = []\n",
        "params_to_update_2 = []\n",
        "params_to_update_3 = []\n",
        "\n",
        "# Not only output layer, \"features\" layers and other classifier layers are tuned.\n",
        "update_param_names_1 = [\"features\"]\n",
        "update_param_names_2 = [\"classifier.0.weight\",\n",
        "                        \"classifier.0.bias\", \"classifier.3.weight\", \"classifier.3.bias\"]\n",
        "update_param_names_3 = [\"classifier.6.weight\", \"classifier.6.bias\"]\n",
        "\n",
        "# store parameters in list\n",
        "for name, param in net.named_parameters():\n",
        "    if update_param_names_1[0] in name:\n",
        "        param.requires_grad = True\n",
        "        params_to_update_1.append(param)\n",
        "        #print(\"params_to_update_1:\", name)\n",
        "\n",
        "    elif name in update_param_names_2:\n",
        "        param.requires_grad = True\n",
        "        params_to_update_2.append(param)\n",
        "        #print(\"params_to_update_2:\", name)\n",
        "\n",
        "    elif name in update_param_names_3:\n",
        "        param.requires_grad = True\n",
        "        params_to_update_3.append(param)\n",
        "        #print(\"params_to_update_3:\", name)\n",
        "\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "        #print(\"no learning\", name)\n",
        "\n",
        "# print(\"-----------\")\n",
        "# print(params_to_update_1)\n",
        "\n",
        "# Learning Rates\n",
        "optimizer = optim.SGD([\n",
        "    {'params': params_to_update_1, 'lr': 1e-4},\n",
        "    {'params': params_to_update_2, 'lr': 5e-4},\n",
        "    {'params': params_to_update_3, 'lr': 1e-3}\n",
        "], momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# training function\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs, device):\n",
        "    \n",
        "    accuracy_list = []\n",
        "    loss_list = []\n",
        "    \n",
        "    # Precondition : Accelerator GPU -> 'On'\n",
        "    #device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"using device：\", device)\n",
        "\n",
        "    # put betwork into GPU\n",
        "    net.to(device)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # epoch loop\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-------------')\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()  # set network 'train' mode\n",
        "            else:\n",
        "                net.eval()   # set network 'val' mode\n",
        "\n",
        "            epoch_loss = 0.0\n",
        "            epoch_corrects = 0\n",
        "\n",
        "            # Before training\n",
        "            if (epoch == 0) and (phase == 'train'):\n",
        "                continue\n",
        "            \n",
        "                      \n",
        "            # batch loop\n",
        "            for inputs, labels in tqdm(dataloaders_dict[phase]):\n",
        "                   \n",
        "                # send data to GPU\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                \n",
        "                # initialize optimizer\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = net(inputs)\n",
        "\n",
        "                    loss = criterion(outputs, labels)  #calcurate loss\n",
        "                    _, preds = torch.max(outputs, 1)  # predict\n",
        "  \n",
        "                    # back propagtion\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                    # update loss summation\n",
        "                    epoch_loss += loss.item() * inputs.size(0)  \n",
        "                    # update correct prediction summation\n",
        "                    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # loss and accuracy for each epoch loop\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_acc = epoch_corrects.float() / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "            \n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "            \n",
        "            if phase == 'val':\n",
        "                accuracy_list.append(epoch_acc.item())\n",
        "                loss_list.append(epoch_loss)\n",
        "            \n",
        "    return accuracy_list, loss_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using device： mps\n",
            "Epoch 1/10\n",
            "-------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 210/210 [00:58<00:00,  3.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 2.3488 Acc: 0.1202\n",
            "Epoch 2/10\n",
            "-------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 901/901 [16:40<00:00,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.8754 Acc: 0.6995\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 210/210 [00:55<00:00,  3.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.7658 Acc: 0.7265\n",
            "Epoch 3/10\n",
            "-------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 901/901 [12:37<00:00,  1.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.1886 Acc: 0.9421\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 210/210 [00:43<00:00,  4.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.6863 Acc: 0.7851\n",
            "Epoch 4/10\n",
            "-------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 901/901 [12:35<00:00,  1.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.1105 Acc: 0.9652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 210/210 [00:43<00:00,  4.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.5774 Acc: 0.8078\n",
            "Epoch 5/10\n",
            "-------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 901/901 [12:34<00:00,  1.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.0780 Acc: 0.9770\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 210/210 [00:44<00:00,  4.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.5104 Acc: 0.8254\n",
            "Epoch 6/10\n",
            "-------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 901/901 [12:34<00:00,  1.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.0523 Acc: 0.9840\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 210/210 [00:42<00:00,  4.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.7030 Acc: 0.7967\n",
            "Epoch 7/10\n",
            "-------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 300/901 [04:12<08:25,  1.19it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/alexanderries/aml_itu/notebooks/VGG16_ft_test3.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/VGG16_ft_test3.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# start training\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/VGG16_ft_test3.ipynb#X54sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m num_epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/VGG16_ft_test3.ipynb#X54sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m accuracy_list, loss_list \u001b[39m=\u001b[39m train_model(net, dataloaders, criterion, optimizer, num_epochs, device)\n",
            "\u001b[1;32m/Users/alexanderries/aml_itu/notebooks/VGG16_ft_test3.ipynb Cell 16\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(net, dataloaders_dict, criterion, optimizer, num_epochs, device)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/VGG16_ft_test3.ipynb#X54sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/VGG16_ft_test3.ipynb#X54sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# batch loop\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/VGG16_ft_test3.ipynb#X54sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mfor\u001b[39;00m inputs, labels \u001b[39min\u001b[39;00m tqdm(dataloaders_dict[phase]):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/VGG16_ft_test3.ipynb#X54sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m        \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/VGG16_ft_test3.ipynb#X54sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39m# send data to GPU\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/VGG16_ft_test3.ipynb#X54sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/VGG16_ft_test3.ipynb#X54sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/aml_itu/utils/StatefarmPytorchDataset.py:94\u001b[0m, in \u001b[0;36mStateFarmDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39m# Apply transformations\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform:\n\u001b[0;32m---> 94\u001b[0m     image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(image)\n\u001b[1;32m     95\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform:\n\u001b[1;32m     96\u001b[0m     label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(label)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torchvision/transforms/v2/_container.py:53\u001b[0m, in \u001b[0;36mCompose.forward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m     51\u001b[0m needs_unpacking \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(inputs) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[39mfor\u001b[39;00m transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 53\u001b[0m     outputs \u001b[39m=\u001b[39m transform(\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m     54\u001b[0m     inputs \u001b[39m=\u001b[39m outputs \u001b[39mif\u001b[39;00m needs_unpacking \u001b[39melse\u001b[39;00m (outputs,)\n\u001b[1;32m     55\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torchvision/transforms/v2/_transform.py:50\u001b[0m, in \u001b[0;36mTransform.forward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m     45\u001b[0m needs_transform_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_needs_transform_list(flat_inputs)\n\u001b[1;32m     46\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_params(\n\u001b[1;32m     47\u001b[0m     [inpt \u001b[39mfor\u001b[39;00m (inpt, needs_transform) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(flat_inputs, needs_transform_list) \u001b[39mif\u001b[39;00m needs_transform]\n\u001b[1;32m     48\u001b[0m )\n\u001b[0;32m---> 50\u001b[0m flat_outputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     51\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform(inpt, params) \u001b[39mif\u001b[39;00m needs_transform \u001b[39melse\u001b[39;00m inpt\n\u001b[1;32m     52\u001b[0m     \u001b[39mfor\u001b[39;00m (inpt, needs_transform) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(flat_inputs, needs_transform_list)\n\u001b[1;32m     53\u001b[0m ]\n\u001b[1;32m     55\u001b[0m \u001b[39mreturn\u001b[39;00m tree_unflatten(flat_outputs, spec)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torchvision/transforms/v2/_transform.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     45\u001b[0m needs_transform_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_needs_transform_list(flat_inputs)\n\u001b[1;32m     46\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_params(\n\u001b[1;32m     47\u001b[0m     [inpt \u001b[39mfor\u001b[39;00m (inpt, needs_transform) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(flat_inputs, needs_transform_list) \u001b[39mif\u001b[39;00m needs_transform]\n\u001b[1;32m     48\u001b[0m )\n\u001b[1;32m     50\u001b[0m flat_outputs \u001b[39m=\u001b[39m [\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(inpt, params) \u001b[39mif\u001b[39;00m needs_transform \u001b[39melse\u001b[39;00m inpt\n\u001b[1;32m     52\u001b[0m     \u001b[39mfor\u001b[39;00m (inpt, needs_transform) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(flat_inputs, needs_transform_list)\n\u001b[1;32m     53\u001b[0m ]\n\u001b[1;32m     55\u001b[0m \u001b[39mreturn\u001b[39;00m tree_unflatten(flat_outputs, spec)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torchvision/transforms/v2/_geometry.py:642\u001b[0m, in \u001b[0;36mRandomRotation._transform\u001b[0;34m(self, inpt, params)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_transform\u001b[39m(\u001b[39mself\u001b[39m, inpt: Any, params: Dict[\u001b[39mstr\u001b[39m, Any]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    641\u001b[0m     fill \u001b[39m=\u001b[39m _get_fill(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fill, \u001b[39mtype\u001b[39m(inpt))\n\u001b[0;32m--> 642\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_kernel(\n\u001b[1;32m    643\u001b[0m         F\u001b[39m.\u001b[39;49mrotate,\n\u001b[1;32m    644\u001b[0m         inpt,\n\u001b[1;32m    645\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams,\n\u001b[1;32m    646\u001b[0m         interpolation\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterpolation,\n\u001b[1;32m    647\u001b[0m         expand\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexpand,\n\u001b[1;32m    648\u001b[0m         center\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcenter,\n\u001b[1;32m    649\u001b[0m         fill\u001b[39m=\u001b[39;49mfill,\n\u001b[1;32m    650\u001b[0m     )\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torchvision/transforms/v2/_transform.py:35\u001b[0m, in \u001b[0;36mTransform._call_kernel\u001b[0;34m(self, functional, inpt, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_kernel\u001b[39m(\u001b[39mself\u001b[39m, functional: Callable, inpt: Any, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m     34\u001b[0m     kernel \u001b[39m=\u001b[39m _get_kernel(functional, \u001b[39mtype\u001b[39m(inpt), allow_passthrough\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 35\u001b[0m     \u001b[39mreturn\u001b[39;00m kernel(inpt, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torchvision/transforms/v2/functional/_geometry.py:996\u001b[0m, in \u001b[0;36mrotate_image\u001b[0;34m(image, angle, interpolation, expand, center, fill)\u001b[0m\n\u001b[1;32m    994\u001b[0m     theta \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(matrix, dtype\u001b[39m=\u001b[39mdtype, device\u001b[39m=\u001b[39mimage\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[1;32m    995\u001b[0m     grid \u001b[39m=\u001b[39m _affine_grid(theta, w\u001b[39m=\u001b[39mwidth, h\u001b[39m=\u001b[39mheight, ow\u001b[39m=\u001b[39mow, oh\u001b[39m=\u001b[39moh)\n\u001b[0;32m--> 996\u001b[0m     output \u001b[39m=\u001b[39m _apply_grid_transform(image, grid, interpolation\u001b[39m.\u001b[39;49mvalue, fill\u001b[39m=\u001b[39;49mfill)\n\u001b[1;32m    998\u001b[0m     new_height, new_width \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:]\n\u001b[1;32m    999\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torchvision/transforms/v2/functional/_geometry.py:572\u001b[0m, in \u001b[0;36m_apply_grid_transform\u001b[0;34m(img, grid, mode, fill)\u001b[0m\n\u001b[1;32m    569\u001b[0m     mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones((shape[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m, shape[\u001b[39m2\u001b[39m], shape[\u001b[39m3\u001b[39m]), dtype\u001b[39m=\u001b[39mfloat_img\u001b[39m.\u001b[39mdtype, device\u001b[39m=\u001b[39mfloat_img\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    570\u001b[0m     float_img \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((float_img, mask), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 572\u001b[0m float_img \u001b[39m=\u001b[39m grid_sample(float_img, grid, mode\u001b[39m=\u001b[39;49mmode, padding_mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mzeros\u001b[39;49m\u001b[39m\"\u001b[39;49m, align_corners\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    574\u001b[0m \u001b[39m# Fill with required color\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[39mif\u001b[39;00m fill \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:4304\u001b[0m, in \u001b[0;36mgrid_sample\u001b[0;34m(input, grid, mode, padding_mode, align_corners)\u001b[0m\n\u001b[1;32m   4296\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   4297\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mDefault grid_sample and affine_grid behavior has changed \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4298\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mto align_corners=False since 1.3.0. Please specify \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4299\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39malign_corners=True if the old behavior is desired. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4300\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSee the documentation of grid_sample for details.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4301\u001b[0m     )\n\u001b[1;32m   4302\u001b[0m     align_corners \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 4304\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mgrid_sampler(\u001b[39minput\u001b[39;49m, grid, mode_enum, padding_mode_enum, align_corners)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# start training\n",
        "num_epochs=10\n",
        "accuracy_list, loss_list = train_model(net, dataloaders, criterion, optimizer, num_epochs, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epoch_num = list(range(10))\n",
        "fig, ax = plt.subplots(facecolor=\"w\")\n",
        "ax.plot(epoch_num, accuracy_list, label=\"accuracy\")\n",
        "ax.plot(epoch_num, loss_list, label=\"loss\")\n",
        "plt.xticks(epoch_num) \n",
        "\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "3c8ad80dbc202ee9aff426fa151d52828bd7b4f3aec4c0ec93048b40e8792c84"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
