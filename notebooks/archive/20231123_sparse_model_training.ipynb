{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmGPfIwRKzFV"
      },
      "source": [
        "# `Setup`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceRf-vSlKzFW",
        "outputId": "cbba2297-3b61-4901-969c-5a663fd2f7e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From https://github.com/RasKrebs/aml_itu\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n",
            "/Users/alexanderries/aml_itu\n",
            "MPS device found.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import datetime as dt\n",
        "from math import ceil\n",
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "try:\n",
        "    # Mounting Colab Drive if possible\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Cloning repo for colab\n",
        "    if 'aml_itu' in os.getcwd():\n",
        "        %cd aml_itu/\n",
        "        !git pull https://github.com/RasKrebs/aml_itu\n",
        "        !git checkout -b sparse_filtering\n",
        "    else:\n",
        "        !git clone -b sparse_test https://github.com/RasKrebs/aml_itu\n",
        "        %cd aml_itu/\n",
        "    os.environ[\"COLAB\"] = \"True\"\n",
        "\n",
        "except:\n",
        "    # Changing directory into aml_itu\n",
        "    if os.getcwd().split('/')[-1] != 'aml_itu': os.chdir(os.path.abspath('.').split('aml_itu/')[0]+'aml_itu')\n",
        "    !git pull origin main --ff-only\n",
        "    os.environ[\"COLAB\"] = \"False\"\n",
        "\n",
        "# Utils Import\n",
        "from utils.helpers import *\n",
        "from utils.StatefarmPytorchDataset import StateFarmDataset\n",
        "\n",
        "\n",
        "# Torch\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "torchvision.disable_beta_transforms_warning()\n",
        "import torchvision.transforms as T\n",
        "from torchvision.transforms import v2\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Install torchinfo, import if it's available\n",
        "try:\n",
        "  import torchinfo\n",
        "except:\n",
        "  !pip install torchinfo\n",
        "  import torchinfo\n",
        "\n",
        "from torchinfo import summary\n",
        "\n",
        "\n",
        "# Printing current working directory\n",
        "print(os.getcwd())\n",
        "\n",
        "# Setting up device\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print (f\"GPU is available\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "    print('MPS device found.')\n",
        "else:\n",
        "    print (\"No GPU available, using CPU instead\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qujmd-H5KzFX"
      },
      "source": [
        "### `Config`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fR4A88qzKzFX"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dataset': {'name': 'state-farm-distracted-driver-detection',\n",
              "  'colab_path': '/content/drive/MyDrive/aml-distracted-drivers-project',\n",
              "  'data': '../state-farm-distracted-driver-detection/driver_imgs_list.csv',\n",
              "  'images': {'train': '../state-farm-distracted-driver-detection/imgs/train',\n",
              "   'test': '../state-farm-distracted-driver-detection/imgs/test'},\n",
              "  'class_mapping': {'c0': 'safe driving',\n",
              "   'c1': 'texting - right',\n",
              "   'c2': 'talking on the phone - right',\n",
              "   'c3': 'texting - left',\n",
              "   'c4': 'talking on the phone - left',\n",
              "   'c5': 'operating the radio',\n",
              "   'c6': 'drinking',\n",
              "   'c7': 'reaching behind',\n",
              "   'c8': 'hair and makeup',\n",
              "   'c9': 'talking to passenger'}},\n",
              " 'outputs': {'path': './outputs'},\n",
              " 'modeling_params': {'batch_size': 32, 'epochs': 100}}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MODEL_NAME = 'SparseFilter_GrayScale'\n",
        "\n",
        "# Loading the config file (if content is in workin directory must mean colab is being used)\n",
        "config = load_config(eval(os.environ[\"COLAB\"]))\n",
        "\n",
        "\n",
        "# Training Images\n",
        "train_img = config['dataset']['images']['train']\n",
        "\n",
        "# Outputting config\n",
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "m3ABOz6Ol0Zl"
      },
      "outputs": [],
      "source": [
        "def save_model(model, model_name, epoch):\n",
        "    \"\"\"Function for saving model\"\"\"\n",
        "    # Model name, with path\n",
        "    timestamp = dt.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    file = f'{model_name}_{timestamp}_epoch_{epoch+1}'\n",
        "    name = os.path.join(config['outputs']['path'], model_name, file)\n",
        "\n",
        "    # Make directory if not exists\n",
        "    if not os.path.exists(os.path.join(os.path.join(config['outputs']['path'], model_name))):\n",
        "        os.makedirs(os.path.join(os.path.join(config['outputs']['path'], model_name)))\n",
        "\n",
        "    # Save model\n",
        "    torch.save(model.state_dict(), f'{name}.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RKyqh-awZCv"
      },
      "source": [
        "## Sparse Filtring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2prAFACAwZCv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import gc\n",
        "gc.collect()\n",
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "from torch.utils.data import Subset\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import random\n",
        "from torch.utils.data import Subset\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import random\n",
        "\n",
        "# Sparse Filter Class\n",
        "class SparseFilter(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(SparseFilter, self).__init__()\n",
        "        self.weights = nn.Parameter(torch.randn(input_dim, output_dim) * 0.5)\n",
        "        self.epsilon = 1e-8\n",
        "\n",
        "    def soft_abs(self, value):\n",
        "        return torch.sqrt(value ** 2 + self.epsilon)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print(x.shape)\n",
        "        #print(self.weights.shape)\n",
        "        first = torch.matmul(x, self.weights)\n",
        "        second = self.soft_abs(first)\n",
        "        third = second / torch.sqrt(torch.sum(second ** 2, axis=0) + self.epsilon)\n",
        "        fourth = third / torch.sqrt(torch.sum(third ** 2, axis=1)[:, None] + self.epsilon)\n",
        "        return torch.sum(fourth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/alexanderries/opt/anaconda3/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "v3_transform = v2.Compose([v2.Compose([\n",
        "      v2.ToPILImage(),\n",
        "      v2.Resize((240, 320)),\n",
        "      v2.Grayscale(num_output_channels=1),\n",
        "      v2.ToTensor(),\n",
        "      v2.Normalize(mean=[0.485], std=[0.229]),\n",
        "      torch.flatten\n",
        "      ])\n",
        "    ])\n",
        "\n",
        "# Load the dataset without transformations\n",
        "train_data = StateFarmDataset(config,\n",
        "                              transform=v3_transform,  # Transformations\n",
        "                              split='train',\n",
        "                              target_transform=None)\n",
        "\n",
        "# Generate random indices for the subset\n",
        "subset_size = 10000\n",
        "indices = torch.randperm(len(train_data)).tolist()\n",
        "subset_indices = indices[:subset_size]\n",
        "\n",
        "# Create a subset\n",
        "train_subset = Subset(train_data, subset_indices)\n",
        "\n",
        "# Create a DataLoader for the subset\n",
        "train_subset_loader = DataLoader(train_data, batch_size=32, num_workers=4, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RvX-JJI9jCpr"
      },
      "outputs": [],
      "source": [
        "def train_step(model, dataloader, optimizer, device, accumulation_steps=4):\n",
        "    \"\"\"Train step for a single epoch with gradient accumulation.\"\"\"\n",
        "\n",
        "    # Losses and accuracies\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    # Initialize the gradient\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for i, data in enumerate(dataloader):\n",
        "\n",
        "        # Extracting data and labels + moving to device\n",
        "        imgs, labels = data\n",
        "        imgs = imgs.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        loss = model(imgs)\n",
        "\n",
        "        # Normalize the loss to account for accumulation\n",
        "        normalized_loss = loss / accumulation_steps\n",
        "\n",
        "        # Backward pass (accumulates gradients over multiple backward steps)\n",
        "        normalized_loss.backward()\n",
        "\n",
        "        # Step with optimizer every 'accumulation_steps' iterations\n",
        "        if (i + 1) % accumulation_steps == 0 or (i + 1) == len(dataloader):\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        # Update train loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Return average train loss\n",
        "    return train_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_training(history, num_epochs=50):\n",
        "\n",
        "    # Generate Figure\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    # Loss Plots\n",
        "    sns.lineplot(y=history['train_loss'], x=list(range(len(history['train_loss']))), ax=axs[0], label='Train Loss')\n",
        "    sns.lineplot(y=history['val_loss'], x=list(range(len(history['val_loss']))), ax=axs[0], label='Validation Loss')\n",
        "    axs[0].set_ylabel('Cross Entropy Loss')\n",
        "    axs[0].set_xlabel('Epochs')\n",
        "    axs[0].set_xlim(0, num_epochs)\n",
        "\n",
        "    # Accuracy Plots\n",
        "    sns.lineplot(y=history['train_acc'], x=list(range(len(history['train_acc']))), ax=axs[1], label='Train Accuracy')\n",
        "    sns.lineplot(y=history['val_acc'], x=list(range(len(history['val_acc']))), ax=axs[1], label='Validation Accuracy')\n",
        "    axs[1].set_ylabel('Accuracy')\n",
        "    axs[1].set_xlabel('Epochs')\n",
        "    axs[1].set_xlim(0, num_epochs)\n",
        "\n",
        "    # Show plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8e9GmdtYjR_i"
      },
      "outputs": [],
      "source": [
        "def train_sparse_filter(model, train_dataloader, optimizer, epochs, device):\n",
        "    \"\"\"Model training method\"\"\"\n",
        "    # History\n",
        "    history = dict(train_loss=[],\n",
        "                   train_acc=[],\n",
        "                   val_loss=[],\n",
        "                   val_acc=[])\n",
        "\n",
        "    # Loop through epochs\n",
        "    for epoch in range(epochs):\n",
        "        print(f'\\nEpoch {epoch+1} of {epochs} started...')\n",
        "\n",
        "        # Set model to train mode and do pass over data\n",
        "        model.train(True)\n",
        "        train_loss = train_step(model, train_dataloader, optimizer, device)\n",
        "\n",
        "        print(f\"Epoch {epoch+1} of {epochs} - Train loss: {train_loss:.5f}\")\n",
        "\n",
        "        # Save model\n",
        "        save_model(model, MODEL_NAME, epoch)\n",
        "\n",
        "        # Save train and val loss/acc\n",
        "        history['train_loss'].append(train_loss)\n",
        "\n",
        "        # Visualize every 5th epoch\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            visualize_training(history, epochs)\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "od6JKwpTjrVc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1 of 50 started...\n",
            "MPS device found.\n",
            "MPS device found.\n",
            "MPS device found.\n",
            "MPS device found.\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "MPS backend out of memory (MPS allocated: 31.71 GB, other allocations: 1.07 GB, max allowed: 36.27 GB). Tried to allocate 3.52 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m/Users/alexanderries/aml_itu/notebooks/20231123_sparse_model_training.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/20231123_sparse_model_training.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(sparse_filter_model1\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlearning_rate)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/20231123_sparse_model_training.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/20231123_sparse_model_training.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m results \u001b[39m=\u001b[39m train_sparse_filter(model\u001b[39m=\u001b[39;49msparse_filter_model1,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/20231123_sparse_model_training.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                 train_dataloader\u001b[39m=\u001b[39;49mtrain_subset_loader,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/20231123_sparse_model_training.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m                 optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/20231123_sparse_model_training.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                 epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/20231123_sparse_model_training.ipynb#X33sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                 device\u001b[39m=\u001b[39;49mdevice)\n",
            "\u001b[1;32m/Users/alexanderries/aml_itu/notebooks/20231123_sparse_model_training.ipynb Cell 12\u001b[0m in \u001b[0;36mtrain_sparse_filter\u001b[0;34m(model, train_dataloader, optimizer, epochs, device)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/20231123_sparse_model_training.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Set model to train mode and do pass over data\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/20231123_sparse_model_training.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m model\u001b[39m.\u001b[39mtrain(\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/20231123_sparse_model_training.ipynb#X33sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m train_loss \u001b[39m=\u001b[39m train_step(model, train_dataloader, optimizer, device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/20231123_sparse_model_training.ipynb#X33sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m of \u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m - Train loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m:\u001b[39;00m\u001b[39m.5f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/20231123_sparse_model_training.ipynb#X33sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Save model\u001b[39;00m\n",
            "\u001b[1;32m/Users/alexanderries/aml_itu/notebooks/20231123_sparse_model_training.ipynb Cell 12\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, dataloader, optimizer, device, accumulation_steps)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/20231123_sparse_model_training.ipynb#X33sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# Step with optimizer every 'accumulation_steps' iterations\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/20231123_sparse_model_training.ipynb#X33sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mif\u001b[39;00m (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m accumulation_steps \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(dataloader):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/20231123_sparse_model_training.ipynb#X33sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/20231123_sparse_model_training.ipynb#X33sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexanderries/aml_itu/notebooks/20231123_sparse_model_training.ipynb#X33sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# Update train loss\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    374\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py:163\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    152\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    154\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    155\u001b[0m         group,\n\u001b[1;32m    156\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    161\u001b[0m         state_steps)\n\u001b[0;32m--> 163\u001b[0m     adam(\n\u001b[1;32m    164\u001b[0m         params_with_grad,\n\u001b[1;32m    165\u001b[0m         grads,\n\u001b[1;32m    166\u001b[0m         exp_avgs,\n\u001b[1;32m    167\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    168\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    169\u001b[0m         state_steps,\n\u001b[1;32m    170\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    171\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    172\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    173\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    174\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    175\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    176\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    177\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    178\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    179\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    180\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    181\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    182\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    185\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py:311\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 311\u001b[0m func(params,\n\u001b[1;32m    312\u001b[0m      grads,\n\u001b[1;32m    313\u001b[0m      exp_avgs,\n\u001b[1;32m    314\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    315\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    316\u001b[0m      state_steps,\n\u001b[1;32m    317\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    318\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    319\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    320\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    321\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    322\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    323\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    324\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    325\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    326\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    327\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py:432\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    430\u001b[0m         denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    431\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 432\u001b[0m         denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39;49m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    434\u001b[0m     param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n\u001b[1;32m    436\u001b[0m \u001b[39m# Lastly, switch back to complex view\u001b[39;00m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 31.71 GB, other allocations: 1.07 GB, max allowed: 36.27 GB). Tried to allocate 3.52 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
          ]
        }
      ],
      "source": [
        "# Define and train the sparse filter model\n",
        "input_dim = 240*320  # Input dimension\n",
        "output_dim = 48*64  # Desired output dimension\n",
        "sparse_filter_model1 = SparseFilter(input_dim, output_dim).to(device)  # Move model to GPU\n",
        "learning_rate = 0.01\n",
        "optimizer = optim.Adam(sparse_filter_model1.parameters(), lr=learning_rate)\n",
        "epochs = 50\n",
        "\n",
        "\n",
        "\n",
        "results = train_sparse_filter(model=sparse_filter_model1,\n",
        "                train_dataloader=train_subset_loader,\n",
        "                optimizer=optimizer,\n",
        "                epochs=epochs,\n",
        "                device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqpxHyB2wZCw"
      },
      "outputs": [],
      "source": [
        "# Save the model weights\n",
        "torch.save(sparse_filter_model1.state_dict(), './outputs/SparseFilterWeights/sparse_filter_model_try4_50epochs.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TCpNU2IoMd6"
      },
      "outputs": [],
      "source": [
        "\n",
        "torch.save(sparse_filter_model1.state_dict(), './drive/MyDrive')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "3c8ad80dbc202ee9aff426fa151d52828bd7b4f3aec4c0ec93048b40e8792c84"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
