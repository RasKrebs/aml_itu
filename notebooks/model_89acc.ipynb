{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GktSpV92-bdd"
      },
      "source": [
        "# `Setup`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P8SxD1ws-bde",
        "outputId": "231c3322-2768-4788-98d4-5c0610037550",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cloning into 'aml_itu'...\n",
            "remote: Enumerating objects: 169, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 169 (delta 3), reused 1 (delta 0), pack-reused 144\u001b[K\n",
            "Receiving objects: 100% (169/169), 178.22 MiB | 29.75 MiB/s, done.\n",
            "Resolving deltas: 100% (68/68), done.\n",
            "/content/aml_itu\n",
            "/content/aml_itu\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "try:\n",
        "    # Mounting Colab Drive if possible\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Cloning repo for colab\n",
        "    !git clone https://github.com/RasKrebs/aml_itu\n",
        "    %cd aml_itu/\n",
        "    os.environ[\"COLAB\"] = \"True\"\n",
        "\n",
        "except:\n",
        "    # Changing directory into aml_itu\n",
        "    if os.getcwd().split('/')[-1] != 'aml_itu': os.chdir(os.path.abspath('.').split('aml_itu/')[0]+'aml_itu')\n",
        "    !git pull origin main\n",
        "    os.environ[\"COLAB\"] = \"False\"\n",
        "\n",
        "# Utils Import\n",
        "from utils.helpers import *\n",
        "from utils.StatefarmPytorchDataset import StateFarmDataset\n",
        "\n",
        "# Printing current working directory\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp7aq5Gr-bdf"
      },
      "source": [
        "### `Config`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BMEPY8Kf-bdg",
        "outputId": "9042856c-feb0-4c69-b0a9-7eee0c8b16ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dataset': {'name': 'state-farm-distracted-driver-detection',\n",
              "  'colab_path': '/content/drive/MyDrive/aml-distracted-drivers-project',\n",
              "  'data': '/content/drive/MyDrive/aml-distracted-drivers-project/state-farm-distracted-driver-detection/driver_imgs_list.csv',\n",
              "  'images': {'train': '/content/drive/MyDrive/aml-distracted-drivers-project/state-farm-distracted-driver-detection/imgs/train',\n",
              "   'test': '/content/drive/MyDrive/aml-distracted-drivers-project/state-farm-distracted-driver-detection/imgs/test'},\n",
              "  'class_mapping': {'c0': 'safe driving',\n",
              "   'c1': 'texting - right',\n",
              "   'c2': 'talking on the phone - right',\n",
              "   'c3': 'texting - left',\n",
              "   'c4': 'talking on the phone - left',\n",
              "   'c5': 'operating the radio',\n",
              "   'c6': 'drinking',\n",
              "   'c7': 'reaching behind',\n",
              "   'c8': 'hair and makeup',\n",
              "   'c9': 'talking to passenger'}},\n",
              " 'outputs': {'path': './outputs'},\n",
              " 'modeling_params': {'batch_size': 32, 'epochs': 100}}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Loading the config file (if content is in workin directory must mean colab is being used)\n",
        "config = load_config(eval(os.environ[\"COLAB\"]))\n",
        "\n",
        "\n",
        "# Training Images\n",
        "train_img = config['dataset']['images']['train']\n",
        "\n",
        "# Outputting config\n",
        "config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjvMI2Gq-bdg"
      },
      "source": [
        "## `Main`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import Compose, Resize, Normalize, Lambda\n",
        "import torchvision.transforms.functional as TF\n",
        "from torch import float32\n",
        "\n",
        "def custom_transforms(image):\n",
        "    # Convert image to float\n",
        "    image = image.to(float32)\n",
        "    # Resize image\n",
        "    image = TF.resize(image, (224, 224))\n",
        "    # Normalize\n",
        "    image = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(image)\n",
        "\n",
        "    return image\n",
        "\n",
        "# Combine custom transformations\n",
        "transform = Compose([Lambda(custom_transforms)])\n",
        "\n",
        "# Creating the dataset with custom transformations\n",
        "train_data = StateFarmDataset(config, split='train', transform=transform)\n",
        "test_data = StateFarmDataset(config, split='test', transform=transform)"
      ],
      "metadata": {
        "id": "661D7Zdz-Pj6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "# Creating the dataset with custom transformations\n",
        "train_data = StateFarmDataset(config, split='train', transform=train_transforms)"
      ],
      "metadata": {
        "id": "Mz0bbQOLgLA-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from utils.StatefarmPytorchDataset import StateFarmDataset"
      ],
      "metadata": {
        "id": "jk6XxiznEjJc"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "BuZyCrGY-wrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import timm\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "label_map = {'c0': 0, 'c1': 1, 'c2': 2, 'c3': 3, 'c4': 4, 'c5': 5, 'c6': 6, 'c7': 7, 'c8': 8, 'c9': 9}\n",
        "\n",
        "\n",
        "# Load the EfficientNet model\n",
        "model_name = 'efficientnet_b5'  # You can choose from b0 to b7\n",
        "efficientnet_model = timm.create_model(model_name, pretrained=True)\n",
        "\n",
        "# Freeze the early layers\n",
        "for param in efficientnet_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace the classifier layer\n",
        "num_ftrs = efficientnet_model.classifier.in_features\n",
        "efficientnet_model.classifier = nn.Linear(num_ftrs, 10)  # Assuming 10 classes\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "efficientnet_model = efficientnet_model.to(device)\n",
        "\n",
        "# Loss Function and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(efficientnet_model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# DataLoader, batch size and worker threads\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=config['modeling_params']['batch_size'], shuffle=True, num_workers = 4)\n",
        "test_loader = DataLoader(test_data, batch_size=config['modeling_params']['batch_size'], shuffle=False)\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, criterion, optimizer, train_loader, num_epochs=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "\n",
        "        for images, label_tuple in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            labels = [label_map[label] for label in label_tuple]\n",
        "            labels = torch.tensor(labels, dtype=torch.long)  # Convert list of integers to a tensor\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_predictions += labels.size(0)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_accuracy = 100 * correct_predictions / total_predictions\n",
        "        print(f'Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
        "\n",
        "\n",
        "# Example of calling the training function\n",
        "train_model(efficientnet_model, criterion, optimizer, train_loader, num_epochs=10)\n"
      ],
      "metadata": {
        "id": "BqXqeQaHVcEx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389,
          "referenced_widgets": [
            "cdf490287a5d49eda9270b35d19c29e4",
            "f196bc8e92ec4062b28054894222801f",
            "87233477e84c4bc39d7ac916f4cc3a5b",
            "5343a3f893c745bbb7cca7efc58477f1",
            "cf6187ef4d2748188593ac05b242685e",
            "409dae10c66b47cf89d8bd42b90199d4",
            "670884048d0741538b0b0751e6362b1e",
            "b5f8f08714a1419db8205b92761e79ec",
            "9773d58a01154957929364c9f16519f4",
            "25616b6f8b894747a1da7d951b05b7fc",
            "bdf5f9c686844d11a66293e2d85cdbae"
          ]
        },
        "outputId": "572519dc-9f7c-45e2-91a5-c4dbdaa4755d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/122M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cdf490287a5d49eda9270b35d19c29e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 565/565 [02:07<00:00,  4.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.3391, Accuracy: 70.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 565/565 [02:08<00:00,  4.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6809, Accuracy: 89.11%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 565/565 [02:10<00:00,  4.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.4935, Accuracy: 92.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 565/565 [02:08<00:00,  4.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.4031, Accuracy: 93.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 565/565 [02:08<00:00,  4.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.3457, Accuracy: 94.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 565/565 [02:11<00:00,  4.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.3035, Accuracy: 95.07%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 565/565 [02:09<00:00,  4.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.2734, Accuracy: 95.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 565/565 [02:13<00:00,  4.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.2520, Accuracy: 95.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 565/565 [02:08<00:00,  4.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.2323, Accuracy: 96.24%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 565/565 [02:08<00:00,  4.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.2156, Accuracy: 96.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def test_model(model, test_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    with torch.no_grad():  # No need to track gradients during testing\n",
        "        for images, label_tuple in test_loader:\n",
        "            labels = [label_map[label] for label in label_tuple]\n",
        "            labels = torch.tensor(labels, dtype=torch.long)\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_predictions += labels.size(0)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct_predictions / total_predictions\n",
        "    print(f'Accuracy on test set: {accuracy:.2f}%')\n",
        "\n",
        "# Test the model\n",
        "test_model(efficientnet_model, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a09kjnB3HuiJ",
        "outputId": "31a34f60-1596-4901-c2aa-60d65204c191"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 54.29%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NEW MODEL\n"
      ],
      "metadata": {
        "id": "sL-G4mHzaDT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import timm\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Model Setup\n",
        "model_name = 'efficientnet_b1'\n",
        "model = timm.create_model(model_name, pretrained=True)\n",
        "num_ftrs = model.classifier.in_features\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Dropout(0.7),\n",
        "    nn.Linear(num_ftrs, 10)\n",
        ")\n",
        "\n",
        "# Loss Function, Optimizer, and Scheduler\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=2e-5)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "# Device Configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Early Stopping Helper\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, verbose=False):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        elif val_loss > self.best_loss:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "\n",
        "early_stopping = EarlyStopping(patience=5, verbose=True)\n",
        "\n",
        "# Training Loop\n",
        "def train_one_epoch(model, train_loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, label_tuple in train_loader:\n",
        "        labels = [label_map[label] for label in label_tuple]\n",
        "        labels = torch.tensor(labels, dtype=torch.long)  # Convert list of integers to a tensor\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    return running_loss / len(train_loader)\n",
        "\n",
        "def validate_model(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, label_tuple in test_loader:\n",
        "            labels = [label_map[label] for label in label_tuple]\n",
        "            labels = torch.tensor(labels, dtype=torch.long)  # Convert list of integers to a tensor\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "    return running_loss / len(test_loader)\n",
        "\n",
        "num_epochs = 25\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion)\n",
        "    val_loss = validate_model(model, test_loader, criterion)\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
        "\n",
        "    early_stopping(val_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "\n",
        "    scheduler.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HCs7i-8aEQJ",
        "outputId": "548a36e0-1459-4ce4-b8a5-d041c334ee15"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25, Train Loss: 0.2064, Val Loss: 0.6483\n",
            "Epoch 2/25, Train Loss: 0.0315, Val Loss: 0.4985\n",
            "Epoch 3/25, Train Loss: 0.0213, Val Loss: 0.5833\n",
            "Epoch 4/25, Train Loss: 0.0212, Val Loss: 0.4472\n",
            "Epoch 5/25, Train Loss: 0.0225, Val Loss: 0.6800\n",
            "Epoch 6/25, Train Loss: 0.0079, Val Loss: 0.5513\n",
            "Epoch 7/25, Train Loss: 0.0129, Val Loss: 0.5934\n",
            "Epoch 8/25, Train Loss: 0.0057, Val Loss: 0.4157\n",
            "Epoch 9/25, Train Loss: 0.0012, Val Loss: 0.4703\n",
            "Epoch 10/25, Train Loss: 0.0008, Val Loss: 0.4331\n",
            "Epoch 11/25, Train Loss: 0.0006, Val Loss: 0.4966\n",
            "Epoch 12/25, Train Loss: 0.0004, Val Loss: 0.4828\n",
            "Epoch 13/25, Train Loss: 0.0003, Val Loss: 0.4632\n",
            "Early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test_model(model, test_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    with torch.no_grad():  # No need to track gradients during testing\n",
        "        for images, label_tuple in test_loader:\n",
        "            labels = [label_map[label] for label in label_tuple]\n",
        "            labels = torch.tensor(labels, dtype=torch.long)\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_predictions += labels.size(0)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct_predictions / total_predictions\n",
        "    print(f'Accuracy on test set: {accuracy:.2f}%')\n",
        "\n",
        "# Test the model\n",
        "test_model(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITHDoyTwrxDW",
        "outputId": "4f0ba978-9c08-4ddc-8bc1-964489b42cc8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 89.69%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_weights_89acc.pth')\n"
      ],
      "metadata": {
        "id": "DL9vtl2bsJh0"
      },
      "execution_count": 25,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cdf490287a5d49eda9270b35d19c29e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f196bc8e92ec4062b28054894222801f",
              "IPY_MODEL_87233477e84c4bc39d7ac916f4cc3a5b",
              "IPY_MODEL_5343a3f893c745bbb7cca7efc58477f1"
            ],
            "layout": "IPY_MODEL_cf6187ef4d2748188593ac05b242685e"
          }
        },
        "f196bc8e92ec4062b28054894222801f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_409dae10c66b47cf89d8bd42b90199d4",
            "placeholder": "​",
            "style": "IPY_MODEL_670884048d0741538b0b0751e6362b1e",
            "value": "model.safetensors: 100%"
          }
        },
        "87233477e84c4bc39d7ac916f4cc3a5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5f8f08714a1419db8205b92761e79ec",
            "max": 122330162,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9773d58a01154957929364c9f16519f4",
            "value": 122330162
          }
        },
        "5343a3f893c745bbb7cca7efc58477f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25616b6f8b894747a1da7d951b05b7fc",
            "placeholder": "​",
            "style": "IPY_MODEL_bdf5f9c686844d11a66293e2d85cdbae",
            "value": " 122M/122M [00:00&lt;00:00, 183MB/s]"
          }
        },
        "cf6187ef4d2748188593ac05b242685e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "409dae10c66b47cf89d8bd42b90199d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "670884048d0741538b0b0751e6362b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5f8f08714a1419db8205b92761e79ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9773d58a01154957929364c9f16519f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25616b6f8b894747a1da7d951b05b7fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdf5f9c686844d11a66293e2d85cdbae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}